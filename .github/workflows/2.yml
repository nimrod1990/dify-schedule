name: Daily News Fetch and Send to WeChat

on:
  schedule:
    - cron: '0 8 * * *'
  workflow_dispatch:

jobs:
  fetch-and-send-news:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install newspaper3k "openai>=1.0" requests lxml[html_clean]

      - name: Fetch News and Interpret with AI
        env:  # 添加环境变量传递
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          SERVERPUSHKEY: ${{ secrets.SERVERPUSHKEY }}
        run: |
          python << 'EOF'
          from openai import OpenAI
          import requests
          from newspaper import Article, Config
          from bs4 import BeautifulSoup
          import os
          
          config = Config()
          config.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
          
          def fetch_news():
              url = 'https://www.bbc.com/innovation/artificial-intelligence'
              
              # 请求页面并解析
              response = requests.get(url)
              soup = BeautifulSoup(response.content, 'html.parser')
      
              article_links = []
              for link in soup.find_all('a', href=True):
                  href = link['href']
                  if href.startswith('/innovation/artificial-intelligence') or href.startswith('https://www.bbc.com/innovation/artificial-intelligence'):
                      article_links.append(f"https://www.bbc.com{href}" if not href.startswith('https://') else href)
              
              # 去重链接（防止重复）
              article_links = list(set(article_links))
              
              news_list = []
              
              # 遍历每个新闻链接，抓取内容
              for link in article_links:
                  article = Article(link, config=config)
                  article.download()
                  article.parse()
                  news_list.append(f"{article.title}\n\n{article.text}")
              
              return "\n\n".join(news_list)
          
          def interpret_news(news):
              print("API Key exists:", bool(os.getenv("OPENAI_API_KEY")))
              client = OpenAI(
                  base_url = "https://api.chatanywhere.org/v1",
                  api_key = os.environ["OPENAI_API_KEY"]
              )
              
              response = client.chat.completions.create(
                  model="gpt-4o-mini",
                  messages=[{
                      "role": "user",
                      "content": f"请用中文结构化呈现这些新闻，不遗漏信息：\n\n{news}"
                  }]
              )
              return response.choices[0].message.content
          
          if __name__ == "__main__":
              try:
                  # 获取新闻内容
                  news = fetch_news()
                  
                  # 让GPT-4o-mini生成总结
                  summary = interpret_news(news)
                  
                  # 获取服务器推送的KEY
                  sckey = os.environ["SERVERPUSHKEY"]
                  
                  # URL编码处理
                  from urllib.parse import quote
                  encoded_msg = f"新闻摘要：\n{summary}"
                  
                  # 发送到微信
                  requests.get(
                      f"https://sctapi.ftqq.com/{sckey}.send",
                      params={
                          "text": "每日新闻摘要",
                          "desp": encoded_msg  # 发送给微信的新闻摘要
                      }
                  )
              except Exception as e:
                  print(f"程序执行失败: {str(e)}")
                  raise
          EOF
          
      - name: Finish
        run: echo "News fetched, interpreted, and sent to WeChat."
